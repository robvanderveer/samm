The SAMM DataSet Project
Wed. morning session.

## goals of the meeting
  * commitment to participate or a commitment to find people who can.
  * list of ideas for where to host it?


## Sidenotes
  * The current data model was designed to support multiple versions of SAMM. It should still be relevant now.
  * companies are interested in SAMM because it's vendor agnostic, as opposed to BSIMM which forces vendor lock-in.
  * companies don't want to be compared in BSIMM as it targets upper-tier companies. Any company not in the elite group will compare unfavourably.

## Challenges:
  * convince people to contribute
  * build a system to support the submission, querying, etc.
  
  * How/Where to host the data? 
  * Howmuch to annonymise the data?
  * If submitting data, you'll need to maintain it. That requires a login which will be tied to a company email address so you lose anonymity.
  * How open should the data be? If it's fully open, the risk is people will just use the data without contributing.


Previously had discussed low and high fidelity versions:
  * low-fi: only submit the final activity scores
  * high-fi: submit all details. This is the most useful and what would be required to match BSIMM functionality.


# Jan's proposal:
  * develop a full samm assessment tool.
  * use some GUID or hash-based obfuscation so that to SAMM, each project is represented as a GUID.
  * use 2-levels of passwds, company-wide one and XX
    * allow companies to delete their passwd file, making the data unavailable. 
  * By using the samm tool, you'll get access to the data.

2 worries:
  * people submitting incorrect data to gain access to their peers' data. Not really an important risk.
  * people maliciously corrupting the data to damage the project. the more serious risk.

  * What about using a gpg-like web of trust so that peers can vouch for others?
    * this might increase the barrier for participation.
 
2 different directions are possible:
  * fully anonymous. No mapping back to the company.
    * concern: lose control over the quality of data. Might render the system unusual.
  * more identifiable: might encourage submitters to be more responsible for the quality of the data.

Need to solve the problem of why people would submit data?
  * initially, we can't give you anything back. what incentive could orgs have to submit.
  * how to 
  * Is there any sense in borrowing from the game world where the more data you submit, the more you unlock access to certain features (e.g. dashboards).
    * the concern is that things should remain open. this is owasp.

should the data be automatically shared?
  * consensus is that orgs should have the option to disable sharing. If you want to compare yourself to others, you need to share your data.
 
how much of the data should be open?
  * summarised data should be open.
  * you should not be able to compare how people are answering questions if you don't submit those.

'static' (aka inherent) and dynamic risk:
  * how about collecting extra information in the tool about the application which is being evaluated. Info about inherent risk of the application, that would allow unlocking further statistics about controls per application risk level.
  * some people only use samm at programme level. So this would not apply. Some also perform samm assessments on an application level. here it could make sense.
  * the approach might allow further differentiation from bsimm.
  * it might make risk-aware orgs more hesitant to share such details.
  * allows answering such questions as: I have a highly sensitive application, am I doing enough, or I have a non-sensitive applicaiton, am I doing too much to protect it.

Should the DataSet project be made an official owasp project?
  * if no good reason to, probably easier to keep it part of samm.
  * lots of red tape to make it an owasp project.

Could we fund this via kickstarter?

## Hosting ideas
not really covered in the end.
  * Problem: it needs to be vendor-agnostic. But so, is owasp and they get hosted somewhere. Why not host it where owasp is?

# brainstorming questionnaire:
  * on-premise solution vs. cloud vs. ??
  * would you be willing to pay for data?
  * familiarity: is your org using samm?
  * use of samm: do you use samm per app or per org?
  * would you be willing to support the project (not necessarily financially, e.g. dev.)
  * are you interested in the overall data or individual data?
  * are you intersted in a reputation system
  * how much time would you expect to spend submitting your data
  * do you want trends in your own submissions
  * how would you like to filter/view the data in the system.
  * are you interested in being contacted back (e.g. more submissions in your demographic) or only 1 direction from submitter to samm.
  * have a checkbox list of metadata they'd be willing to submit. include all.
  * questions should include a degree of importance to the participants. how important is each feature to you?
  * are you willing to be publicly listed as a company participating submitting data?
  * open questions where people can add their own comments.

# general consensus
  * the dataset project is vital to the continued success of samm.

# followup ideas: 
  * publish the list of requirements for an MVP. 
    * from there we figure out which controls are required to achieve the level of protection required.
  * create a survey we can send out to samm practitioners to elicit concerns. have a very rough draft by the end of the week. 
  * work out a few sketches of the 2 models, fully private, open. Share it with samm practitioners to give them an idea of what's possible in each.

